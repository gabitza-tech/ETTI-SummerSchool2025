{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbED1s2P/BCGcWrFTr3Lgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabitza-tech/ETTI-SummerSchool2025/blob/main/Students_MachineLearning_Intro_ImbalancedClasses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Imbalanced Dataset Example - Binary Classification\n",
        "\n",
        "In the real world, data is rarely **clean** or **perfectly balanced**.  \n",
        "Some of the common challenges we face include:  \n",
        "\n",
        "- ‚öñÔ∏è **Imbalanced classes** ‚Äî certain outcomes are much rarer than others.  \n",
        "- ‚ùì **Missing values** ‚Äî incomplete information across different attributes.  \n",
        "- üåç **Domain shifts** ‚Äî differences between training and test data distributions.  \n",
        "\n",
        "---\n",
        "To illustrate how to handle imbalanced data in Python, let‚Äôs explore the **Bank Marketing Dataset**. This publicly available dataset contains information about bank customers, with the target variable indicating whether a client subscribed to a term deposit after receiving a marketing call (‚Äúyes‚Äù vs. ‚Äúno‚Äù)."
      ],
      "metadata": {
        "id": "RshKOmGOY0qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to install this library in order to fetch the dataset we need\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "utOCgZaZkD0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This dataset has a similar format in the end to the previous one from scikit-learn.\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "\n",
        "bank_marketing = fetch_ucirepo(id=222)\n",
        "\n",
        "# Separate the target labels from the rest of the features\n",
        "x = bank_marketing.data.features\n",
        "y = bank_marketing.data.targets\n",
        "\n",
        "# Show some dataset metadata\n",
        "print(bank_marketing.metadata)\n",
        "print(bank_marketing.variables)\n"
      ],
      "metadata": {
        "id": "v139mCCviQYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1\n",
        "\n",
        "### Tasks\n",
        "1. Check dataset size.\n",
        "2. Check number of features.\n",
        "3. Check number of classes.\n",
        "4. Check class distribution.\n",
        "5. Check for missing data.\n"
      ],
      "metadata": {
        "id": "Qr6hCAw1dpDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE HERE\n",
        "\n",
        "# Shape of data and number of features\n",
        "\n",
        "# Number of classes\n",
        "\n",
        "# Class Distribution\n",
        "\n",
        "# Check for missing data"
      ],
      "metadata": {
        "id": "rDGRKd60jT6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2\n",
        "\n",
        "For most of these tasks, look at the previous exercise!\n",
        "\n",
        "### Tasks:\n",
        "\n",
        "1. Handle missing features. (can we simply drop samples?)\n",
        "2. Preprocess features categorical to numerical. - Hint: use `OneHotEncoder` or `LabelEncoder`;\n",
        "3. Split dataset in train and test sets. (70-30 split)\n",
        "4. Scale your data. - Whatever scaler you want\n",
        "4. Train a logistic regression model.\n",
        "5. How long does training take?\n",
        "5. Check accuracy.\n",
        "6. Check precision, recall and f1-score."
      ],
      "metadata": {
        "id": "o7aB0qiek-3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE HERE FOR MISSING DATA + FEATURE & LABEL ENCODING\n",
        "# import necessary libraries for Encoding Features and Labels\n",
        "\n",
        "# Save encoded features and labels in variables x_encoded and y_encoded\n",
        "print(x_encoded[:2])\n",
        "print(set(y_encoded))\n"
      ],
      "metadata": {
        "id": "aGelusQDlxl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE HERE FOR DATA SPLITTING\n",
        "# Necessary imports\n",
        "\n",
        "# use the train-test split function from scikit-learn\n",
        "\n",
        "# DATA SCALING - use the scalers used in previous exercises - save your data as x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "0lUhWDSymeIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE HERE FOR TRAINING a Logistic Regression Model\n",
        "# Necessary imports for training model + evaluation metrics like the report, accuracy score, f1-score\n",
        "\n",
        "# Train and save predictions in a y_pred variable\n",
        "y_pred = ...\n",
        "\n",
        "# Evaluate your train model - save f1, acc\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(...))\n",
        "f1 = f1_score(...) # Calculate macro"
      ],
      "metadata": {
        "id": "t-hQ2hwvmvYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's plot a confusion matrix\n",
        "\n",
        "Using a combination of scikit-learn, seaborn and matplotlib. Let's first show you how you can do that."
      ],
      "metadata": {
        "id": "d2gFzlk5nrMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(...) # YOU HAVE TO FILL THIS PART ;)\n",
        "\n",
        "# Plot using seaborn heatmap\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eJT8Wg1hnvqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Imbalance Techniques\n"
      ],
      "metadata": {
        "id": "ovqjocTSoeLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Random Undersampling\n",
        "\n",
        "Taking in consideration that one class has a **majority**, what we can do as a very simple technique is to simply **remove randomly** from that class until we obtain an equal number of samples in both classes. - we are **REMOVING** training data on purpose, in order to avoid **OVERFITTING** the majority class.\n",
        "\n",
        "# Exercise 3\n",
        "\n",
        "### Tasks\n",
        "\n",
        "1. What is the new number of samples for each class?\n",
        "2. How much data did we remove?\n",
        "3. Train a new logistic regression model - save predictions in `y_pred_rus`\n",
        "4. How long does training take?\n",
        "4. Evaluate the model with the new data."
      ],
      "metadata": {
        "id": "m7zTLfZo3Eyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 1Ô∏è‚É£ Random Undersampling\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_rus, y_rus = rus.fit_resample(x_train, y_train) # New data\n",
        "\n",
        "# Train a logistic regression model with the new data - save your predictions in y_pred_rus\n",
        "...\n",
        "y_pred_rus = ...\n",
        "\n",
        "# Evaluate the new model, save f1_rus, acc_rus\n",
        "\n",
        "f1_rus = ... # calculate macro"
      ],
      "metadata": {
        "id": "h4ZLALO7odl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Random Oversampling\n",
        "\n",
        "Taking in consideration that one class has a **minority**, what we can do as a very simple technique is to simply **randomly repeat** samples from that class until we obtain an equal number of samples in both classes. - we are **ADDING** training data on purpose, in order to avoid **UNDERFITTING** the minority class.\n",
        "\n",
        "# Exercise 4\n",
        "\n",
        "### Tasks\n",
        "\n",
        "1. What is the new number of samples for each class?\n",
        "3. Train a new logistic regression model - save predictions in `y_pred_ros`\n",
        "4. How long does training take?\n",
        "4. Evaluate the model with the new data."
      ],
      "metadata": {
        "id": "cKiDQXPLpEub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "# 1Ô∏è‚É£ Random Undersampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
        "\n",
        "# Write your training code here - save your predictions in y_pred_ros\n",
        "# ...\n",
        "y_pred_ros = ...\n",
        "\n",
        "# Evaluate your model, save f1_ros, acc_ros for later comparisons\n",
        "f1_ros = ... # calculate macro"
      ],
      "metadata": {
        "id": "yP5TQaqopGF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train the Logistic Regression Model with the class balancing function\n",
        "\n",
        "Most methods nowadays have a parameter that can put a bigger weight/importance on minority classes, in order to give them equal importance to the more presents clases. This is a simple method and it only need to add the `class_output='balanced'` in the initialization of the `LogisticRegression` function.\n",
        "\n",
        "# Exercise 5\n",
        "\n",
        "### Tasks\n",
        "\n",
        "1. What is the number of samples for each class?\n",
        "3. Train a new logistic regression model - save predictions in `y_pred_bal`\n",
        "4. How long does training take?\n",
        "4. Evaluate the model with the new data."
      ],
      "metadata": {
        "id": "y3fXkLQ2nCIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE HERE\n",
        "# Balanced Logistic Regression Model training\n",
        "clf_bal = LogisticRegression(max_iter=500, class_weight='balanced')\n",
        "...\n",
        "\n",
        "# Predict and evaluate, save your predictions in y_pred_bal\n",
        "y_pred_bal = ...\n",
        "\n",
        "# Evaluate your model here, save f1_bal, acc_bal\n",
        "..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE3zNzXlnBAi",
        "outputId": "a4983805-a384-4376-b21e-8d7be5f439c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.85      0.91     11977\n",
            "           1       0.42      0.81      0.55      1587\n",
            "\n",
            "    accuracy                           0.85     13564\n",
            "   macro avg       0.69      0.83      0.73     13564\n",
            "weighted avg       0.91      0.85      0.87     13564\n",
            "\n",
            "Accuracy: 0.8464317310527868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Imbalance Techniques comparison\n",
        "\n",
        "Let's plot some confusion matrices for each case, side-by-side. You have minimal *code filling* to do.\n",
        "\n",
        "# Exercise 6\n",
        "\n",
        "### Tasks\n",
        "\n",
        "1. What is the best method?\n",
        "2. Also print some info about each methods f1-score, acc, time taken, etc.\n",
        "\n",
        "### OPTIONAL\n",
        "3. Plot a graph containing the AUROC curve for all 4 cases (unbalanced, undersampling, oversampling, balanced). Make the curves of different colors, with an associated legend. Search what you need in order to plot such a curve, you can obtain auroc/precision/recall values easily with `sklearn.metrics`."
      ],
      "metadata": {
        "id": "YmApjNEw7D5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data - fill the necessary variables\n",
        "preds = {\n",
        "    'Original Logistic': ...,\n",
        "    'Balanced Class Weight': ...,\n",
        "    'Random Undersampling': ...,\n",
        "    'Random Oversampling': ...\n",
        "}\n",
        "\n",
        "# Create 1 row, 4 columns plot\n",
        "fig, axes = plt.subplots(1, 4, figsize=(20,5))\n",
        "\n",
        "for ax, (title, pred) in zip(axes, preds.items()):\n",
        "    cm = confusion_matrix(...) # FILL THE NECESSARY VARIABLES\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'], ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# CODE HERE\n",
        "# Print some more info about each methods performance, acc, f1-score, etc.\n",
        "..."
      ],
      "metadata": {
        "id": "y1dQGaoPqxai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE HERE\n",
        "# PLOT A GRAPHIC CONTAINING ALL 4 AUROC CURVES\n",
        "..."
      ],
      "metadata": {
        "id": "Gk7-8HWq8vKo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}